

# 课设项目策划书：高速公路实时车流监控与套牌车预警平台 (v2.1 完整执行版)



**核心架构原则：**

1. **计算与存储分离**：
   - **服务器 1 (`pipeline-algo`)**：负责高负载计算（Flume/Kafka/Flink/Spark）。
   - **服务器 2 (`db-app`)**：负责存储落盘（MySQL/MyCat/Redis）和 对外服务（Flask API）。
2. **职责明确**：
   - **同学 B & C**：专注“生产数据”并写入存储，**严禁**开发 HTTP 接口。
   - **同学 D**：**全权负责**后端 API 开发，屏蔽底层复杂性。
   - **同学 A**：负责全栈贯通（数据源头 + 前端展示）。

------



## 1. 👥 4人团队分工 (RACI)



| **角色**               | **负责人** | **核心职责 (Responsible)**                                   | **交付物**                           |
| ---------------------- | ---------- | ------------------------------------------------------------ | ------------------------------------ |
| **前端 & 管道 (全栈)** | **同学 A** | 1. **数据源**：Python模拟流 -> Flume -> Kafka (`traffic-raw`) 2. **前端**：开发数据大屏与交互查询页面 (Vue/React) | Kafka Topic, 前端网页                |
| **存储架构师 (主)**    | **同学 B** | 1. **数据库**：在 `db-app` 搭建 MySQL双节点 + MyCat 分片 2. **入库ETL**：编写 Flink Job (Java)，消费 Kafka -> Sink to MyCat | MyCat (`traffic_data` 表)            |
| **算法工程师 (辅)**    | **同学 C** | 1. **实时报警**：编写 Flink Job (Java)，检测套牌车 -> Sink to Redis 2. **离线模型**：Spark ML 训练预测模型 -> 保存模型文件 | Redis (`traffic:warnings`), 模型文件 |
| **后端 API 开发**      | **同学 D** | 1. **统一接口**：开发 Flask Web 服务，统一提供查询、报警、预测 API 2. **资源整合**：加载 C 的模型，连接 B 的数据库 | Flask API 服务 (`/api/*`)            |

------



## 2. 🛰️ 服务器部署架构

#### **服务器 1: `pipeline-algo` (计算与消息中心)**

- **负责人**：**同学 A** (环境运维), **B & C** (提交任务)
- **运行服务**：
  - **Zookeeper & Kafka**: (A) 消息中间件，Topic: `traffic-raw`
  - **Flume**: (A) 日志采集
  - **Flink Cluster**: (B & C) 运行 `KafkaToMyCat` 和 `TaopaiDetect` 任务
  - **Spark**: (C) 离线训练任务



#### **服务器 2: `db-app` (存储与服务中心)**

- **负责人**：**B** (DB/MyCat), **C** (Redis部署), **D** (Flask)
- **运行服务**：
  - **MySQL 实例 1**: 端口 `3306` (B负责)
  - **MySQL 实例 2**: 端口 `3307` (B负责，虚拟节点/分片)
  - **MyCat**: 端口 `8066` (B负责，核心分片入口)
  - **Redis**: 端口 `6379` (C负责，**已移至此服务器**)
  - **Flask API**: 端口 `5000` (D负责，统一后端接口)

------

## 3. 📅 详细任务清单 (Action Items)

#### **🧑‍💻 同学A (前端 & 管道)**

1. **数据生产**：保证 `pipeline-algo` 上的 `simulate.py` 和 `traffic-raw` 主题 7x24小时稳定产出数据。
2. **前端开发**：根据 D 提供的 API 接口文档，开发数据大屏和查询页面。
3. **交付物**：`traffic-raw` (Kafka Topic), 前端网页。



#### **🧑‍💻 同学 B (存储 & 入库)**

1. **MySQL 双实例**：在 `db-app` 上配置 `3306` 和 `3307` 两个 MySQL 实例。
2. **MyCat 分片**：配置 `schema.xml`，实现按 `KKMC` (卡口名称) 或 `SFZRKMC` 将数据分片到这两个 MySQL 实例。
3. **Flink 入库**：编写 Flink Java 代码，读取 `pipeline-algo` 的 Kafka，通过 JDBC (Druid池) 写入 `db-app` 的 MyCat (`8066`)。
   - *注意：你的 Flink 代码运行在 `pipeline-algo`，但写入的目标 IP 是 `db-app`。*



#### **🧑‍💻 同学 C (算法 & 缓存)**

1. **Redis 部署**：在 `db-app` 上安装并启动 Redis。
2. **Flink 实时报警**：编写 Flink Java 代码（状态编程），检测套牌车（同车牌短时间出现在不同卡口），将报警信息 `LPUSH` 到 `db-app` 的 Redis List 中。
3. **Spark 预测**：在 `pipeline-algo` 上训练模型，并将模型文件传输给 D 同学（或者放在共享目录），供 Flask 加载。



#### **🧑‍💻 同学 D (后端 API)**

1. **Flask 搭建**：在 `db-app` 上搭建 Flask 服务。
2. **业务接口**：连接本机的 MyCat (`localhost:8066`)，为前端提供 SQL 查询接口（流量排名、交互查询）。
3. **算法接口**：
   - 连接本机的 Redis (`localhost:6379`)，读取报警队列，提供给前端。
   - 加载 C 同学提供的 Spark/算法模型，提供流量预测 API。
4. **CORS 配置**：务必在 Flask 中配置跨域允许，因为我的前端是独立运行的。





## 4. 📖 详细执行计划 (Step-by-Step)





### 阶段 0：项目“握手协议” (第1天，A & D)



- **目标**：定义“前端”与“后端”的唯一契约。
- **行动 (同学 A)**：编写并发布 `API.md` 接口文档，明确 JSON 字段格式。
- **行动 (同学 D)**：确认 `API.md` 可实现性，如有异议立即提出。

------



### 阶段 1：数据管道打通 (同学 A) - [✅ 已完成]



- **状态**：`pipeline-algo` 上的 Kafka Topic `traffic-raw` 已稳定产出 7x24h 数据。
- **运维详情**：
  - Kafka 地址：`localhost:9092` (仅限 `pipeline-algo` 内部访问)。
  - Topic：`traffic-raw`。

------



好的，这是为您严格按照**阶段 3** 的格式标准重写完善的 **阶段 2 (同学 B)** 和 **阶段 4 (同学 D)** 的详细执行指南。

请直接复制以下内容更新到您的团队文档中。

------



### 阶段 2：存储架构搭建与入库 (第2-5天，同学 B)



这是**阶段 2：存储架构搭建与入库**的详细执行指南，专为 **同学 B (存储架构师)** 准备。

这一阶段是整个项目的“地基”，你将在一台服务器 (`db-app`) 上通过**“虚拟节点”**技术模拟出一个分布式的数据库集群，并打通实时数据入库链路。

- **目标**：在 `db-app` 服务器上构建 MyCat 分片集群，并让 Flink 实时将 Kafka 数据写入其中。
- **工期**：第 2 - 5 天
- **输入**：Kafka Topic `traffic-raw` (来自 `pipeline-algo:9092`)。
- **输出**：MyCat 8066 端口可查的 `traffic_data` 表（数据已自动分片）。



#### 📝 详细步骤指南



**第一步：部署双实例 MySQL (虚拟分片节点)**

- **背景**：为了演示“分布式存储”，我们需要两个数据库节点。由于只有一台服务器 `db-app`，我们需要在这台机器上同时运行**两个** MySQL 进程，分别监听 `3306` 和 `3307` 端口。

- **⚠️ 关键警告**：(参考 `朱少行-后端.pdf` p.14) **严禁使用 MySQL 8.0**。Ubuntu 默认 apt 安装的是 8.0，它的大小写敏感配置和认证插件与 MyCat 1.6 兼容性极差。**必须手动安装 MySQL 5.7** (推荐使用 tar.gz 解压版或 docker)。

- **操作指引** (在 `db-app` 服务器执行)：

  1. **环境清理**：如果 `db-app` 上已经有 MySQL 8.0，请先彻底卸载。

  2. 多实例配置 (my.cnf)：

     你需要创建两个配置文件，例如 /etc/mysql/my3306.cnf 和 /etc/mysql/my3307.cnf。

     - **实例 1 (Shard 1)**: Port: `3306`, Datadir: `/var/lib/mysql_3306`, Socket: `/tmp/mysql_3306.sock`。
     - **实例 2 (Shard 2)**: Port: `3307`, Datadir: `/var/lib/mysql_3307`, Socket: `/tmp/mysql_3307.sock`。

  3. 初始化与启动：

     分别初始化两个数据目录，并启动两个 mysqld 进程。

  4. 建库建表：

     连接这两个实例（mysql -u root -P 3306 和 -P 3307），在两个实例中执行完全相同的 SQL：

     SQL

     ```
     CREATE DATABASE traffic_db;
     USE traffic_db;
     -- 建表结构需参考 API.md 和 字段说明
     CREATE TABLE traffic_data (
         id VARCHAR(50) PRIMARY KEY, -- GCXH
         kkmc VARCHAR(50),           -- 分片键
         hphm VARCHAR(20),
         gcsj DATETIME,              -- 关键：时间字段
         -- ... 其他字段 ...
         INDEX idx_gcsj (gcsj)       -- 必须加时间索引，否则查询慢
     );
     ```

**第二步：配置 MyCat 分片中间件**

- **背景**：MyCat 是数据库的“路由器”。它对外伪装成一个 MySQL，对内将数据切分到 3306 和 3307。

- **参考资料**：`朱少行-后端.pdf` (p.6-8) - 他详细记录了 `schema.xml` 的配置。

- **操作指引** (在 `db-app` 服务器执行)：

  1. **安装 JDK 1.8**：MyCat 运行依赖。

  2. 配置 schema.xml (核心)：

     你需要修改 /usr/local/mycat/conf/schema.xml。

     - **定义数据节点 (dataNode)**：定义 `dn1` 对应数据库实例1，`dn2` 对应数据库实例2。

     - **定义数据主机 (dataHost)**：配置 `writeHost` 分别指向 `127.0.0.1:3306` 和 `127.0.0.1:3307`。

     - **定义逻辑表 (Table)**：

       XML

       ```
       <table name="traffic_data" dataNode="dn1,dn2" rule="sharding-by-kkmc" />
       ```

  3. 配置 rule.xml (分片算法)：

     必须使用一致性哈希 (murmur)，这样数据分布最均匀。

     XML

     ```
     <tableRule name="sharding-by-kkmc">
         <rule>
             <columns>KKMC</columns>
             <algorithm>murmur</algorithm>
         </rule>
     </tableRule>
     ```

  4. **启动与测试**：

     - 启动：`./mycat start`
     - 测试：用 Navicat 连接 `db-app:8066`。如果你往 `traffic_data` 插入一条数据，它应该只会出现在 3306 或 3307 中的一个，而不是两个都有。

**第三步：编写 Flink 入库程序 (Java)**

- **背景**：数据还在 Kafka 里，我们需要一个“搬运工”把它实时写入 MyCat。**注意：你的 Flink 代码将提交到 `pipeline-algo` 服务器运行，通过网络写入 `db-app`。**

- **参考资料**：`杨研博-数据管道.pdf` (p.15-18) - 他的 `MysqlConnect` 类就是基于 Druid 连接池实现的，直接复用代码结构。

- **代码逻辑 (Java)**：

  - **Source**: `KafkaSource` 连接 `localhost:9092` (因为 Flink 和 Kafka 同在 `pipeline-algo`)，消费 `traffic-raw`。
  - **Transform**: `Map` 或 `FlatMap`。
    - 将 `\t` 分隔的字符串切分。
    - **重要**：将 `GCSJ` (字符串) 解析为 Java `Timestamp` 对象，否则写入 MySQL `DATETIME` 字段会报错。
  - **Sink**: `RichSinkFunction` (JDBC Sink)。
    - **连接池**：使用 Alibaba Druid (`DruidDataSource`)。
    - **JDBC URL**: `jdbc:mysql://<db-app的内网IP>:8066/MYETCDB` (连接 MyCat，不是 MySQL)。
    - **SQL**: `INSERT INTO traffic_data (...) VALUES (...)`。
    - **Batch**: 建议设置 `batchSize` (如 50 条一刷)，提高吞吐量。

- 调试提示：

  如果发现写入慢或报错，先检查 db-app 的防火墙是否开放了 8066 端口给 pipeline-algo。

**第四步：配置 MySQL 自动清理 (TTL)**

- **背景**：模拟数据是 7x24 小时生成的，如果不清理，你的磁盘几天就会爆满。

- 操作指引：

  在 3306 和 3307 两个 MySQL 实例中，分别执行以下 SQL 开启定时任务：

  SQL

  ```
  -- 1. 开启事件调度器
  SET GLOBAL event_scheduler = ON;
  -- 2. 创建每日清理事件 (只保留最近3天)
  CREATE EVENT auto_clean_traffic
  ON SCHEDULE EVERY 1 DAY
  DO DELETE FROM traffic_data WHERE gcsj < DATE_SUB(NOW(), INTERVAL 3 DAY);
  ```



#### 🗓️ 交付物清单 (Checklist)



- [ ] **双端口 MySQL**: `netstat -ntlp | grep 3306` 和 `grep 3307` 均有进程。
- [ ] **MyCat 服务**: 端口 `8066` 可连接，且 `SELECT * FROM traffic_data` 不报错。
- [ ] **Flink 任务**: 提交到集群，状态为 `RUNNING`，且 MyCat 中数据量在持续增加。
- [ ] **全局表数据**: 将同学 A 提供的 `kkmc_dimension.csv` 导入到了 MyCat 的 `kkmc_info` 表中。

------

### 阶段 3：算法与预警 (第2-5天，同学 C)



这是**阶段 3：算法实现与缓存部署**的详细执行指南，专为 **同学 C (算法工程师)** 准备。

根据 v2.2 架构，你的工作重心是“计算”和“模型”。你将在 `pipeline-algo` 服务器上运行计算任务，但将结果写入 `db-app` 服务器上的 Redis。

- **目标**：实现“套牌车实时报警”链路，并训练“流量预测”模型。
- **工期**：第 2 - 5 天
- **输入**：Kafka Topic `traffic-raw` (流数据) + `master_data_expanded.csv` (历史数据)。
- **输出**：
  1. Redis 中的 `traffic:warnings` 告警队列。
  2. 可供 Flask 加载的 Spark ML 模型文件。



#### 📝 详细步骤指南

##### 第一步：部署 Redis (在 db-app 服务器)



**背景**：为了让数据持久化与计算解耦，我们将 Redis 部署在存储节点 `db-app` 上。你的 Flink 任务将远程写入它。

**操作指引 (在 `db-app` 服务器执行)**：

1. **安装 Redis**：

   Bash

   ```
   sudo apt update
   sudo apt install redis-server
   ```

2. **配置远程访问**： 默认 Redis 只允许本地连接。你需要修改配置文件允许 pipeline-algo 连接。

   - 编辑配置：`sudo nano /etc/redis/redis.conf`
   - 修改绑定地址：找到 `bind 127.0.0.1 ::1`，改为 `bind 0.0.0.0` (允许所有IP连接)。

3. **重启并验证**：

   - 重启：`sudo systemctl restart redis-server`
   - 测试：在 `db-app` 上输入 `redis-cli ping`，应返回 `PONG`。



##### 第二步：编写 Flink 实时预警程序 (Java)



**背景**：这是本项目的**最大亮点**。你需要用 Flink 的**状态编程 (Stateful Processing)** 来检测异常。

**逻辑核心**： “如果同一车牌 (`keyBy HPHM`)，在 **5分钟内** 出现在了 **两个不同的卡口**，则判定为套牌车。”

**参考资料**：`杨再润-组长.pdf` (p.3-4) - 重点参考他的 Flink 逻辑。

**代码逻辑 (Java)**：

1. **Source**: 连接 Kafka `localhost:9092`，消费 `traffic-raw`。

2. **Transform**: 解析字符串，提取 `HPHM` (车牌), `KKMC` (卡口), `GCSJ` (时间)。

3. **KeyBy**: 按车牌号分组 -> `.keyBy(data -> data.hphm)`。

4. **Process (核心)**: 使用 `KeyedProcessFunction`。

   - **定义状态**: `ValueState<TrafficRecord> lastAppearanceState;` (存储上一次该车牌出现的记录)。

   - **状态定义 (关键修改)**：在 `open()` 方法中定义状态时，必须设置 **State TTL (生存时间)**。

     - ```java
       // 定义状态配置：10分钟后自动过期 (因为我们只关心5分钟内的套牌行为)
       StateTtlConfig ttlConfig = StateTtlConfig
           .newBuilder(Time.minutes(10))
           .setUpdateType(StateTtlConfig.UpdateType.OnCreateAndWrite)
           .setStateVisibility(StateTtlConfig.StateVisibility.NeverReturnExpired)
           .build();
       
       ValueStateDescriptor<TrafficRecord> descriptor = new ValueStateDescriptor<>("lastAppearance", TrafficRecord.class);
       descriptor.enableTimeToLive(ttlConfig); // 启用 TTL，防止 Flink 内存爆炸
       lastAppearanceState = getRuntimeContext().getState(descriptor);
       ```

   - **处理逻辑 (`processElement`)**:

     1. 读取 `lastAppearanceState`。
     2. 如果状态为空 (第一次出现)，更新状态为当前记录。
     3. 如果状态不为空：
        - 计算当前时间与 `lastAppearanceState` 时间的差值。
        - **判定规则**：如果 `时间差 < 5分钟` **且** `当前卡口 != 上次卡口`：
          - **触发告警**：生成一条告警字符串 (JSON格式)。
          - `out.collect(alarmJson);`
        - 更新状态为当前记录。

5. **Sink**: `RedisSink` (使用 `flink-connector-redis`)。

   - **Host**: `<db-app的内网IP>` (注意不是 localhost)。
   - **Port**: `6379`。
   - **Command**: `LPUSH` (将告警推入 List 头部)。
   - **Key**: `traffic:warnings` (严格遵守 API 文档定义的 Key)。
   - (注意：标准的 Flink Redis Connector 不支持 `LTRIM` 裁剪列表。为了防止 Redis 爆满，建议同学 C 在代码中做一个简单的**策略优化**，或者由同学 D 在读取时清理。但为了课设简单，我们可以**给 Redis 设置最大内存策略**)。

6. **(补充操作)**：**配置 Redis 自动淘汰策略 (在 db-app 执行)** 为了防止 Redis 内存爆满，修改 `/etc/redis/redis.conf`：

   - 找到 `maxmemory`，设置为 `512mb` (给系统留活路)。
   - 找到 `maxmemory-policy`，设置为 `allkeys-lru` (内存满时，自动删除最旧的数据)。
   - 重启 Redis：`sudo systemctl restart redis-server`。

**交付物验证**： 在 `pipeline-algo` 运行 Flink 任务，然后在 `db-app` 上运行 `redis-cli lrange traffic:warnings 0 -1`，看是否有数据进来。



##### 第三步：Spark ML 离线预测 (PySpark)



**背景**：利用历史数据训练一个简单的线性回归模型，预测未来的流量。

**操作指引 (在 `pipeline-algo` 服务器执行)**：

1. **准备环境**：确保已安装 Spark 和 PySpark (`pip install pyspark`)。

2. **编写脚本 `train_model.py`**：

   Python

   ```
   from pyspark.sql import SparkSession
   from pyspark.ml.feature import VectorAssembler, StringIndexer
   from pyspark.ml.regression import LinearRegression
   from pyspark.ml import Pipeline
   
   # 1. 初始化
   spark = SparkSession.builder.appName("TrafficPrediction").getOrCreate()
   
   # 2. 读取数据 (同学A提供的清洗后数据)
   df = spark.read.csv("master_data_expanded.csv", header=True, inferSchema=True)
   
   # 3. 特征工程 (简化版: 预测流量 = f(卡口, 小时, 周末))
   indexer = StringIndexer(inputCol="KKMC", outputCol="kkmc_index")
   assembler = VectorAssembler(
       inputCols=["kkmc_index", "hour", "is_weekend"],
       outputCol="features"
   )
   
   # 4. 定义模型
   lr = LinearRegression(featuresCol="features", labelCol="traffic_count")
   
   # 5. 构建 Pipeline 并训练
   pipeline = Pipeline(stages=[indexer, assembler, lr])
   model = pipeline.fit(df)
   
   # 6. 保存模型 (关键交付物)
   model.save("traffic_flow_model")
   ```

3. **执行训练**：运行脚本，生成 `traffic_flow_model` 文件夹。



##### 第四步：移交交付物给同学 D



**这一步至关重要**，因为现在 API 由 D 负责开发，他需要你的成果才能写代码。

1. **Redis 信息**：告诉 D，Redis 地址是 `localhost:6379` (对 D 来说是本机)，Key 是 `traffic:warnings`。
2. **模型文件**：将训练好的 `traffic_flow_model` 文件夹打包发送给 D (或者拷贝到 `db-app` 服务器)。



#### 🗓️ 交付物清单 (Checklist)



- [ ] **Redis 服务**: 在 `db-app` 上运行，且 `pipeline-algo` 可以远程连接。
- [ ] **Flink 告警任务**: 代码中实现了“同车不同卡口”检测逻辑，状态为 `RUNNING`。
- [ ] **告警数据落地**: Redis 中 `traffic:warnings` 列表里有实时的 JSON 数据。
- [ ] **预测模型**: `traffic_flow_model` 文件夹已生成，并验证可以被加载。

----

### 阶段 4：后端 API 服务开发 (第4-8天，同学 D)



这是**阶段 4：后端 API 服务开发**的详细执行指南，专为 **同学 D (后端开发工程师)** 准备。

在 v2.0 架构中，你是连接底层数据（B和C的成果）与前端展示（同学 A 的成果）的关键枢纽。你的工作是屏蔽底层的复杂性（分片数据库、缓存队列、机器学习模型），对外暴露标准的 HTTP JSON 接口。

- **目标**：搭建 Flask 服务，实现 `API.md` 中定义的 **8个核心接口**。
- **工期**：第 4 - 8 天
- **输入**：
  1. MyCat 数据 (`traffic_data` 表, 端口 8066)。
  2. Redis 数据 (`traffic:warnings` 队列, 端口 6379)。
  3. Spark ML 模型文件 (`traffic_flow_model` 文件夹)。
- **输出**：一个支持跨域访问 (CORS) 的 RESTful API 服务。



##### 📝 详细步骤指南



**第一步：搭建 Flask 环境与基础架构**

- **背景**：你需要一个轻量级的 Web 框架来托管 API。

- **操作指引** (在 `db-app` 服务器执行)：

  1. **安装依赖**：

     Bash

     ```
     pip install flask flask-cors pymysql redis pyspark numpy pandas
     ```

     *注意：运行 PySpark 需要服务器上配置好 Java 环境（B同学搭建 MyCat 时应该已经装了 JDK 1.8，确认一下 `java -version`）。*

  2. 项目结构初始化：

     建议创建如下目录结构：/home/student_d/backend/ 下包含 app.py (入口), config.py (配置), db_utils.py (工具), traffic_flow_model/ (模型)。

  3. 配置 app.py (核心)：

     初始化 Flask 并配置跨域，这是前端能访问你的关键。

     Python

     ```
     from flask import Flask
     from flask_cors import CORS
     app = Flask(__name__)
     # 允许所有来源跨域，生产环境不推荐，但课设环境必须这样配，否则前端同学 A 会报错
     CORS(app, resources={r"/api/*": {"origins": "*"}})
     ```

**第二步：实现业务查询接口 (对接 MyCat)**

- **背景**：前端的大屏图表和查询页面需要从数据库读数据。你需要连接 B 同学搭建的 MyCat（端口 8066），而不是直接连 MySQL。
- **参考资料**：`朱少行-后端(Flask)与数据库(MyCat).pdf.pdf` (p. 9-13) - 重点参考他的 `utils` 类（动态 SQL 拼接）和 `MyDb` 类。
- **代码逻辑 (Python)**：
  1. **数据库连接 (`config.py`)**：配置 Host 为 `127.0.0.1`，Port 为 `8066`，Database 为 `MYETCDB`。
  2. **实现 `[接口 1] 交互式查询` (`POST /api/query`)**：
     - **难点**：前端传来的条件是动态的。
     - **逻辑**：接收 JSON 参数 -> 构建 SQL `WHERE` 子句 (如 `hphm LIKE '%{}%'`) -> 加上 `LIMIT` 分页 -> 执行 SQL -> 返回结果。
  3. **实现 `[接口 2-6] 大屏统计接口`**：
     - 编写聚合查询 (`GROUP BY`) SQL。例如卡口流量 Top10: `SELECT kkmc, COUNT(*) FROM traffic_data GROUP BY kkmc ORDER BY ... LIMIT 10`。

**第三步：实现实时告警接口 (对接 Redis)**

- **背景**：C 同学的 Flink 任务已经把告警推到了 Redis 的 List 中，你需要取出来给前端展示。

- **操作指引**：

  1. **连接 Redis**：

     Python

     ```
     import redis
     r = redis.Redis(host='127.0.0.1', port=6379, decode_responses=True)
     ```

  2. **实现 `[接口 7] 实时套牌车告警` (`GET /api/warnings/realtime`)**：

     - **逻辑**：前端大屏通常需要显示“最新”的几条告警。
     - **操作**：使用 `LRANGE` 命令读取 List 的前 10 条：`r.lrange("traffic:warnings", 0, 9)`。

**第四步：实现流量预测接口 (对接 Spark 模型)**

- **背景**：C 同学训练好了模型，你需要加载它来预测未来流量。

- **⚠️ 性能风险控制**：SparkSession 的启动非常慢且消耗内存。**严禁**在每次 API 请求时才创建 SparkSession。**必须**在 Flask 启动时（全局）初始化 Spark，并**严格限制内存**以防挤爆数据库。

- **代码逻辑**：

  1. **全局加载模型 (`app.py` 顶部)**：

     Python

     ```
     from pyspark.sql import SparkSession
     from pyspark.ml import PipelineModel
     
     # 1. 初始化 Spark (只做一次，严格限制内存！)
     spark = SparkSession.builder \
         .appName("FlaskPredictionService") \
         .master("local[1]") \
         .config("spark.driver.memory", "512m") \
         .getOrCreate()
     
     # 2. 加载模型 (C同学提供的文件夹路径)
     try:
         traffic_model = PipelineModel.load("./traffic_flow_model")
         print(">>> 模型加载成功！")
     except Exception as e:
         print(f">>> 模型加载失败: {e}")
     ```

  2. **实现 `[接口 8] 未来流量预测` (`GET /api/predict/flow`)**：

     - **逻辑**：接收参数 (`kkmc`, `hour`) -> 构造 Spark DataFrame (单行) -> 调用 `model.transform()` -> 提取预测值 -> 返回 JSON。



##### 🗓️ 交付物清单 (Checklist)

- [ ] **Flask 服务运行中**: `netstat -ntlp | grep 5000` 有进程。
- [ ] **MyCat 连通性**: 调用 `/api/stats/kkmc_count` 能返回 JSON 数据。
- [ ] **Redis 连通性**: 调用 `/api/warnings/realtime` 能返回 C 同学生成的告警数据。
- [ ] **Spark 模型加载**: Flask 启动日志显示“模型加载成功”，且预测接口能在 1秒内返回结果。
- [ ] **API 文档对齐**: 你的接口路径、参数和返回格式与同学 A 写的 `API.md` **完全一致**。



##### 📚 参考资料

- **`项目技术接口规范与交付物定义.md` (即 API.md)**：这是你的开发圣经，字段名一个字母都不能错，否则前端同学 A 会找你麻烦。
- **`朱少行-后端.pdf`**：p. 9-13 (Flask 代码结构)，p. 14 (并发延时查询思路)。
- **`杨再润-组长.pdf`**：p. 7 (API 设计风格参考)。

------



### 阶段 5：前端集成与联调 (第6-10天，同学 A)



- **目标**：完成最终 UI 并对接 D 的 API。
- **工作区**：同学 A 的本地开发环境 -> 最终部署。

**详细步骤**：

1. **Mock 开发**：依据 `API.md` 开发 React/Vue 页面，先用假数据填充。
2. **真实联调**：
   - **唯一后端地址**：`http://db-app:5000` (即 D 的服务)。
   - **不再连接** 8066 (MyCat) 或 5001 (旧规划)。
3. **验证**：
   - **大屏图表**：是否有数据？(验证 B 的 MyCat 链路)
   - **告警列表**：是否滚动更新？(验证 C 的 Redis 链路)
   - **预测功能**：是否返回值？(验证 D 的模型加载)

------



### 5. ⚠️ 常见问题预案 (Troubleshooting)



1. **Flink 连不上 Kafka？**
   - (针对 B/C) 检查代码里是不是写了 `localhost:9092`。如果写了公网 IP 必挂。
2. **MyCat 查不到刚写入的数据？**
   - 这是 MyCat 弱事务特性导致的。告诉同学 A 或者 D，查询时可以尝试加一点延时，或者接受秒级延迟。
3. **db-app 服务器卡死？**
   - (针对 D) 检查 Flask 里的 Spark 内存限制是否生效 (`512m`)。
   - (针对 B) 检查 MySQL 的 binlog 是否撑爆了磁盘。

------



### 6. 🔗 数据流转全景图

```Plaintext
[模拟脚本(A)] --(写入)--> [traffic.log] --(Flume)--> [Kafka @pipeline-algo]
                                                          |
              +-------------------------------------------+
              |                                           |
        (B: Flink入库)                              (C: Flink报警)
              |                                           |
              v                                           v
    [MyCat @db-app:8066] <-- (分片存储) --> [Redis @db-app:6379]
              ^                                           ^
              |                                           |
              +------------ [Flask API (D) @db-app:5000] -+
                                    |
                                    v
                           [前端浏览器 (同学 A)]
```