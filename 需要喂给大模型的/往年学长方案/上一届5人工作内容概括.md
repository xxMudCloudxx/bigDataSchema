# 刘冰峰-前端(数据大屏).pdf



刘冰峰同学负责 **WEB 前端数据大屏**的设计与实现。



### 主要职责与工作流程



1. **技术预研（第一周）**
   - 学习 Vue 框架和 Echarts 技术。
   - 搭建了项目的主页静态页面（index.html）。
   - 研究了 Dreamweaver 和 jQuery 等辅助工具。
2. **技术选型与实现（第二周）**
   - 放弃了初步的静态页面方案，转而研究基于 `vue+echarts` 的大屏项目。
   - 最终选定 `go-view` 作为一个开源可视化前端方案，因为它支持数据实时更新。
3. **数据对接与联调（第三、四周）**
   - **定义数据格式**：负责整理所有图表组件所需的数据格式（如日期、频次等），并向后端同学（朱少行）提出API数据要求。
   - **后端数据解析**：负责解析后端返回的 JSON 数据，并将其填充到 Echarts 图表中。
   - **解决跨域问题（CORS）**：在设置 Axios 请求时遇到跨域问题。他通过封装 Axios 请求函数，并与后端同学沟通，在后端响应头中添加 `Access-Control-Allow-Origin`，成功解决了该问题。
   - **实现图表定时刷新**：实现了图表的定时刷新功能。



### 解决的关键技术问题



- **图表抖动**：在修改数据后，发现图表会发生抖动，变化不顺滑。通过研究源项目，发现是 `watch` 监听了屏幕改动，他通过修改代码解决了此问题。
- **后端并发问题**：在联调后期，发现地图数据与车辆总体数据不一致，数据存在几十秒的延迟。他与后端同学（朱少行）沟通，定位到是 MyCat 并发查询导致的问题，最终通过将查询逻辑修改为查询本地时间5秒前的数据解决了“卡壳”现象。
- **图表功能迭代**：
  - 根据与杨再润同学的交流，将 `right-top` 图表修改为支持三条曲线。
  - 由于后端传来的 `right-center` 图表数据不能保证顺序，他编写了 `mysort` 排序函数在前端进行排序。
  - 根据团队开会决议，将一个图表更换为 3D 可互动图表。
- **辅助后端**：在后端 Kafka 环节出现 IP:端口 检测问题时，他编写了一个 `pymysql` 脚本来辅助后端同学进行检测。



### 最终部署



- 将纯静态的主页部署在 Cloudflare 上以加快访问速度。
- 数据大屏的主体功能通过内网穿透部署在公网，并准备了本地部署作为演示备用方案。

------



# 高成-前端(交互式查询页面).pdf



高壬成同学负责**前端的交互式查询页面**。



### 主要职责与工作流程



1. **技术预研**
   - 由于缺乏前端知识，他花费了两周时间学习了前端基础知识和 Vue 框架。
2. **页面开发与迭代**
   - **初期误解**：最初，他搭建的页面是从后端请求所有数据，然后在**前端进行查询**。
   - **对接调整**：在与后端朱少行同学对接后，他意识到需要将查询条件**传递给后端**，由后端完成查询。他补充了前后端数据传输的知识，并重构了页面。
3. **功能实现（根据团队建议）**
   - 在小组会议后，他根据同学建议对查询页面进行了功能迭代：
   - **动态条件**：增设了查询条件，并实现了自动从后端获取数据（如“收费站出口名称”）并填充到下拉选择框中的功能。
   - **分页查询**：增设了分页查询功能，每页显示100条数据。
   - **便捷时间查询**：添加了日期选择器组件，以替代手动输入时间。
   - **重置与下载**：增加了“条件重置”和“下载”功能，允许用户将查询结果下载为不同类型的文件。

------



# 朱少行-后端(Flask)与数据库(MyCat).pdf



朱少行同学负责**整个后端和数据库（MyCat）的工作**，为数据大屏（刘冰峰）和交互式查询（高壬成）提供 API 接口。



### 主要职责与工作流程



1. **数据库搭建（MySQL & MyCat）**
   - 在三个节点上安装了 MySQL 5.7。
   - 搭建了 MyCat 集群，并配置了主从复制（node3为主, node1为从）和读写分离。
2. **数据库分库分表设计**
   - **数据分析**：对数据字段进行了分析（如 `SFZCKMC` 字段只有四种取值）。
   - **方案设计**：最终采用了“解决方案-2”，即**按 `SFZRKMC`（入口收费站）进行水平分片**，使用一致性哈希 `sharding-by-murmur` 规则。
   - **全局表**：额外设计了 `cp_map`（车牌-地区映射）全局表，用于统计车辆来源地。
3. **后端 API 开发 (Flask)**
   - 使用 Flask 框架搭建后端服务。
   - **增量查询设计**：为提高数据大屏的查询效率，设计了增量查询。其思想是后端维护一个全局信息表，每次只查询上次请求到当前请求之间的数据变化，然后同步到全局表中。他编写了 `solution` 类和 `MyDB` 类来实现此逻辑。
   - **交互式查询接口**：实现了交互式查询的后端逻辑。编写了 `utils` 类，用于将前端（高壬成）传来的查询条件字典转换为 SQL 查询语句。



### 解决的关键技术问题



- **MyCat 并发问题**：在测试中发现，数据查询（SELECT）请求有时会先于数据插入（INSERT）执行，导致查询结果为 NULL。他推测这是 MyCat 的并发控制问题。
- **解决方案**：采用**延时查询**的策略，即每次收到查询请求后，查询当前时刻 1 秒前的数据，以确保数据插入总在查询之前完成。
- **环境问题**：详细记录了在 Ubuntu 系统上安装 MySQL 5.7 遇到的坑（如8.0版本大小写不敏感配置问题）。
- **MyCat 配置**：详细总结了 MyCat 的配置（如 `sharding-by-intfile` 支持字符串类型需要显示设置）。

------



# 杨再润-组长-预测与报警(LSTM-Flink).pdf



杨再润同学是**小组组长**，他负责**在线车流量报警**和**离线车流量预测**两大功能。



### 主要职责与工作流程



1. **在线车流量报警（Flink + Redis）**
   - **Flink 实时计算**：搭建 Flink 集群，编写 Flink 程序从 Kafka 读取数据。通过定义 Watermark 来处理事件时间，并使用1秒时长的滑动窗口 统计各出站口的车流量。
   - **Redis 缓存**：将 Flink 的计算结果（报警信息）Sink 到 Redis 中。他选择 Redis 是因为其极高的读写性能和“定时过期”特性，非常适合时效性强的报警信息，优于 HBase 或 Kafka。
2. **离线车流量预测（HBase + LSTM）**
   - **HBase 存储设计**：搭建了 HBase 集群。设计了 `ETC_raw` 表（存实时数据）和 `ETC_static` 表（存用于模型训练的静态数据）。
   - **神经网络模型**：设计了一个5层的 LSTM 神经网络（2个LSTM层，2个Dropout层，1个Dense层）用于预测车流量。
   - **模型训练**：使用公开数据集，按分钟统计车流量，对数据进行预处理（如处理“伪缺失”数据和正则化），训练出的模型准确率达到 92.77%。
3. **后端 API (Flask) 与前端页面**
   - 使用 Flask 编写了后端 API 接口（如 `/alarm`, `/right-top`, `/bgpredict`），用于向前端提供报警和预测数据。
   - 设计了**离线预测页面**，用于展示预测条件（最近9分钟车流量）和预测结果（下1分钟车流量）。



### 解决的关键技术问题



- **HDFS 部署问题**：在华为云 ECS 上部署 HDFS 时，因公网和内网地址冲突导致集群外无法访问。
- **解决方案**：最终通过 **Docker** 在一台机器上虚拟出 Hadoop 和 HBase 集群，并通过端口映射解决了该问题。
- **安全问题**：在开发过程中服务器被黑客入侵。吸取教训后，他重新配置了安全组白名单访问，提升了整个项目的安全意识。

------



# 杨研博-数据管道(Kafka-Flume-Flink).pdf



杨研博同学负责**数据源头的工作**，包括**实时数据流模拟**和**Kafka数据缓存**，搭建了完整的数据接入管道。



### 主要职责与工作流程



1. **大数据环境搭建**
   - 负责在 `node4` 服务器上搭建 Kafka, Flume, Flink, Zookeeper 等数据管道所需组件。
2. **实时流数据模拟**
   - 编写了 `input_logs.py` 和 `single_log.py` 两个 Python 脚本。
   - `single_log.py` 负责产生单条日志，`input_logs.py` 负责循环调用并控制时间间隔，模拟流式数据写入 `rawETC.log` 文件。
   - **解决序号问题**：解决了 `XH`（序号）变量在多次调用 `single_log.py` 时被重置为1的问题。他采用的方案是，在 `input_logs.py` 中维护 `XH` 变量，并通过系统参数将其传递给 `single_log.py`。
3. **Kafka 生产者 (Flume)**
   - 配置了 `file2kafka.conf` 文件。
   - 使用 Flume 的 `TAILDIR` Source 实时监控 `rawETC.log` 文件的追加内容。
   - 使用 `KafkaSink` 将数据发送到 Kafka Broker 的 `rawETC` 主题中。
4. **Kafka 消费者 (Flink)**
   - 他编写了两个 Flink 消费者程序（Java）。
   - **Mycat Sink**：编写 Flink 程序，从 Kafka 消费数据，进行 `flatMap` 转换，并使用 **Druid 连接池** 将数据 Sink（写入）到 Mycat 数据库。
   - **HBase Sink**：编写了另一个 Flink 程序，将数据 Sink 到 HBase。



### 解决的关键技术问题与调优



- **环境搭建**：解决了 Zookeeper 因云服务器虚拟网卡无法启动（通过 `quorumListenOnALLIPs=true` 解决） 和 Kafka 因 ZK 路径配置错误无法创建 Topic 的问题。
- **数据错误**：解决了 Kafka 中出现未知来源的重复数据问题，发现是由于未清理旧的 Kafka `/logs` 目录导致，通过启动前移除日志目录解决。
- **Kafka 调优**：
  - **内存**：将 Kafka 堆内存（`KAFKA_HEAP_OPTS`）从 1G 调优至 2G。
  - **生产者**：为提高可靠性和吞吐量，修改了 `buffer.memory` (64M), `acks` (-1), `compression.type` (snappy), `linger.ms` (50)，并开启了幂等性。
- **JVM 调优**：
  - **StringTable**：由于模拟数据大量使用字符串，他通过 `-XX:StringTableSize=200000` 增大了 Flink 消费者的 StringTable 桶数量。
  - **GC 调优**：设置了新生代内存占比，并选择 G1 回收器，设置 `-XX:MaxTenuringThreshold=8` 控制对象晋升。