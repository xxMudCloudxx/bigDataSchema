好的，同学 D。这是一份更新后的《团队虚拟机报告.md》。

我已将你刚刚完成的工作（Flask 部署、端口变更至 8088、MyCat 联调成功、Mock 状态）整理到了 **`db-app` 服务器** 的章节中，并更新了底部的 **跨服务器联调状态**。

你可以直接复制以下内容，覆盖掉原来的文件，然后提交到 Git 给队友看。

***

# pipeline-algo服务器的团队文档 (用于同步给 B、C 同学)

**主题：** `pipeline-algo` 服务器状态更新 - (同学A)

**日期：** 2025-11-18

**概要：**
我已完成 `pipeline-algo` 服务器 的**完整数据管道搭建**。Zookeeper, Kafka, Flume 均已启动并联调通过。数据源 `6.simulate.py` 也已在后台运行。

服务器 1: `pipeline-algo` (计算与消息中心)：112.124.59.217，用户名root，密码B4171yyds

**服务器信息：**

1.  **操作系统：** Ubuntu 22.04
2.  **核心依赖：** OpenJDK 1.8 (已安装)

## 数据源(同学A)

1.  **Zookeeper (v3.5.7)：**
    - **安装目录：** `/usr/local/kafka`
    - **配置位置：** `/usr/local/kafka/config/server.properties`
    - 状态：**运行中** (Standalone 模式)
    - 端口：`2181`

2.  **Kafka (v2.4.1)：**
    - **安装目录：** `/usr/local/kafka`
    - **配置位置：** `/usr/local/kafka/config/server.properties`
    - 状态：**运行中**
    - Zookeeper 依赖：已连接 `localhost:2181`
    - **(关键修正)** **网络配置：**
        * 为解决 `LEADER_NOT_AVAILABLE` 错误，已将 `listeners` 配置为 `PLAINTEXT://localhost:9092`。
        * **已移除** `advertised.listeners` 公网 IP 配置。
    - **内存配置：** 保持 1G 堆内存限制 (`-Xmx1G -Xms1G`)。

3.  **Flume (v1.9.0) 管道：**
    - **安装目录：** `/usr/local/flume`
    - **采集配置：** `/usr/local/flume/jobs/file2kafka.conf`
    - 状态：**运行中**
    - `Source`：`TAILDIR` 成功监控 `/var/log/traffic.log`。
    - `Sink`：`KafkaSink` 成功连接 `localhost:9092`。

4.  **数据源 (`6.simulate.py`)：**
    - **脚本目录：** `~/datapipe/`
    - 状态：**运行中**
    - 正在向 `/var/log/traffic.log` 持续写入数据。

5.  **数据管道运维配置**
    - 位置：**`/etc/logrotate.d/traffic-pipe`**
    - 策略：`daily` 切割，`rotate 2` 保留最近2天日志。

6.  **下游须知 (同学 B 和 C) - (!!! 重大更新 !!!)**
    * 根据我们的架构，你们的 Flink 作业 和 Kafka 运行在**同一台** `pipeline-algo` 服务器上。
    * 你们连接 Kafka Broker 的 **唯一地址** 必须是：`localhost:9092`。
    * (已废弃) **请不要** 使用 `<公网IP>:9092`，这会导致 `LEADER_NOT_AVAILABLE` 错误。
    * 你们要消费的 **Topic** 是：`traffic-raw`。

## Flink实时计算(同学B)

- **Flink 版本**: 1.13.6 (安装于 /usr/local/flink)
- **运行任务**: KafkaToMyCatJob
- **任务状态**: **RUNNING**
- **功能描述**:
  - 消费本机 Kafka traffic-raw 主题。
  - 解析清洗数据。
  - 通过公网 JDBC 写入 db-app 的 MyCat。
- **部署路径**: /home/student_b/TrafficMonitor-1.0-SNAPSHOT.jar
- **关键配置**: 使用 MySQL 5.1.49 驱动以兼容 MyCat 1.6。

---

# db-app服务器的团队文档 (主要是 B、C、D 同学使用)

**用途：** 分布式数据库、后端 API、Web 服务
**IP 地址：** 121.196.226.161
**访问凭证：** 用户名 root，密码 B4171yyds

### 1. 物理存储层 (Docker MySQL) (维护人: B)

我们在单机上通过 Docker 模拟了双节点物理存储：
- **节点 1 (分片 A)**: 端口 3306 (MySQL 5.7)
- **节点 2 (分片 B)**: 端口 3307 (MySQL 5.7)
- **维护策略**: 已开启 Event Scheduler，每日凌晨 3:00 自动删除 3 天前数据 (TTL)。

### 2. 逻辑分片层 (MyCat 中间件) (维护人: B)

这是对外暴露的唯一数据库入口。
- **服务端口**: **8066** (数据读写端口)
- **分片规则**: 逻辑库 `MYETCDB`，表 `traffic_data`，分片键 `KKMC` (一致性哈希)。
- **字符集**: utf8。

### 3. 后端 API 服务 (Flask) (维护人: D) ✅ **(12-04 新增)**

我已完成后端基础架构搭建，并成功打通了 MyCat 数据链路。

- **运行状态**: **运行中 (Running)**
- **服务端口**:5000 
- **部署目录**: `/home/student_d/backend/`
- **对外 Base URL**: `http://121.196.226.161:5000`
- **接口实现进度**:
  - **[已完成]** 接口 1-6 (业务查询/图表统计)：已连接本机 MyCat (8066)，SQL 逻辑已验证通过。
  - **[Mock中]** 接口 7-8 (实时告警/流量预测)：目前返回 Mock 假数据，等待 C 同学完成 Redis 和 Spark 模型后接入。
- **注意事项**:
  - 目前 MyCat 中数据可能为空（返回 `[]` 或 `0`），这是正常的，等待 B 同学 Flink 入库后即可显示真实数据。

### 4. 数据库连接指南 (供参考)

Flask 应用部署在本机 (db-app)，连接配置如下：

| 配置项       | 值        | 说明                   |
| ------------ | --------- | ---------------------- |
| **Host**     | 127.0.0.1 | Flask 与 MyCat 同服    |
| **Port**     | **8066**  | **千万别连 3306/3307** |
| **User**     | root      |                        |
| **Password** | 123456    |                        |
| **Database** | MYETCDB   | 逻辑库名               |

------

## 🔄 跨服务器联调状态

1. **网络连通性**:
   - pipeline-algo -> db-app: **已通** (TCP 8066)。
   - 公网 -> db-app (API): **已通** (TCP 5000 已放行)。

2. **数据链路**:
   - Simulate.py (A) -> Flume (A) -> Kafka (A) -> Flink (B) -> MyCat (B) -> **Flask (D)**。
   - **Flask (D) -> 前端 (A)**: 接口已暴露，前端可开始对接。

3. **当前阻塞点**:
   - 等待 **同学 B** 的 Flink 任务持续写入数据，以便 API 返回非空结果。
   - 等待 **同学 C** 部署 Redis 和提供 Spark 模型文件，以便移除 API Mock 状态。
