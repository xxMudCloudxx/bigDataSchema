# pipeline-algo服务器的团队文档 (用于同步给 B、C 同学)

**主题：** `pipeline-algo` 服务器状态更新 - (同学A)

**日期：** 2025-11-18

**概要：**
我已完成 `pipeline-algo` 服务器 的**完整数据管道搭建**。Zookeeper, Kafka, Flume 均已启动并联调通过。数据源 `6.simulate.py` 也已在后台运行。

服务器 1: `pipeline-algo` (计算与消息中心)：112.124.59.217，用户名root，密码B4171yyds

**服务器信息：**

1.  **操作系统：** Ubuntu 22.04
2.  **核心依赖：** OpenJDK 1.8 (已安装)

## 数据源(同学A)

1.  **Zookeeper (v3.5.7)：**

    - **安装目录：** `/usr/local/kafka`

      **配置位置：** `/usr/local/kafka/config/server.properties`

    * 状态：**运行中** (Standalone 模式)
    * 端口：`2181`

2.  **Kafka (v2.4.1)：**

    - **安装目录：** `/usr/local/kafka`
    - **配置位置：** `/usr/local/kafka/config/server.properties`

    * 状态：**运行中**
    * Zookeeper 依赖：已连接 `localhost:2181`
    * **(关键修正)** **网络配置：**
        * 为解决 `LEADER_NOT_AVAILABLE` 错误，已将 `listeners` 配置为 `PLAINTEXT://localhost:9092` INFO KafkaConfig values: ... listeners = PLAINTEXT://localhost:9092]。
        * **已移除** `advertised.listeners` 公网 IP 配置。
    * **内存配置：** 保持 1G 堆内存限制 (`-Xmx1G -Xms1G`)。

3.  **Flume (v1.9.0) 管道：**

    - **安装目录：** `/usr/local/flume`
    - **采集配置：** `/usr/local/flume/jobs/file2kafka.conf`

    * 状态：**运行中**
    * `Source`：`TAILDIR` 成功监控 `/var/log/traffic.log`。
    * `Sink`：`KafkaSink` 成功连接 `localhost:9092`。

4.  **数据源 (`6.simulate.py`)：**

    - **脚本目录：** `~/datapipe/`

    * 状态：**运行中**
    * 正在向 `/var/log/traffic.log` 持续写入数据。

5.  数据管道运维配置

    - 位置：**`/etc/logrotate.d/traffic-pipe`**
    - 这个配置文件里定义了核心策略：
      - **`daily`**：每天检查并切割一次。
      - **`rotate 2`**：只保留最近 2 份日志，更早的自动删除（实现了你说的“2天”清理效果）。
      - **目标文件**：监控的是 `/var/log/traffic.log`。

6.  第一阶段的下游须知**下游须知 (同学 B 和 C) - (!!! 重大更新 !!!)**

    * 根据我们的架构，你们的 Flink 作业 和 Kafka 运行在**同一台** `pipeline-algo` 服务器上。

    * 你们连接 Kafka Broker 的 **唯一地址** 必须是：`localhost:9092`。

    * (已废弃) **请不要** 使用 `<公网IP>:9092`，这会导致 `LEADER_NOT_AVAILABLE` 错误。

    * 你们要消费的 **Topic** 是：`traffic-raw`。


## Flink实时计算(同学B)

- **Flink 版本**: 1.13.6 (安装于 /usr/local/flink)
- **运行任务**: KafkaToMyCatJob
- **任务状态**: **RUNNING**
- **功能描述**:
  - 消费本机 Kafka traffic-raw 主题。
  - 解析清洗数据。
  - 通过公网 JDBC 写入 db-app 的 MyCat。
- **部署路径**: /home/student_b/TrafficMonitor-1.0-SNAPSHOT.jar
- **关键配置**: 使用 MySQL 5.1.49 驱动以兼容 MyCat 1.6。

# db-app服务器的团队文档 (主要是 B、C 同学存储数据使用)

**用途：** 分布式数据库、后端 API、Web 服务
**IP 地址：** 121.196.226.161
**访问凭证：** 用户名 root，密码 B4171yyds

### 1. 物理存储层 (Docker MySQL) (维护人: B)

我们在单机上通过 Docker 模拟了双节点物理存储：

- **节点 1 (分片 A)**:
  - 容器名: mysql-n1
  - 端口映射: 3306:3306 (宿主机端口:容器端口)
  - 版本: MySQL 5.7
- **节点 2 (分片 B)**:
  - 容器名: mysql-n2
  - 端口映射: 3307:3306 (宿主机端口:容器端口)
  - 版本: MySQL 5.7
- **维护策略**: 已开启 Event Scheduler，每日凌晨 3:00 自动删除 3 天前数据 (TTL)。

### 2. 逻辑分片层 (MyCat 中间件) (维护人: B)

这是对外暴露的唯一数据库入口。

- **安装目录**: /usr/local/mycat
- **服务端口**: **8066** (数据读写端口), 9066 (管理端口)
- **分片规则**:
  - 逻辑库: MYETCDB
  - 逻辑表: traffic_data
  - 分片键: KKMC (卡口名称)
  - 算法: murmur (一致性哈希)
- **字符集**: 强制配置为 utf8，已解决中文乱码问题。

### 3. 数据库连接指南 (供同学 D 开发 Flask 使用) ⚠️

**同学 D 请务必阅读：**

你的 Flask 应用部署在本机 (db-app)，连接数据库时请使用以下配置：

| 配置项       | 值           | 说明                                                         |
| ------------ | ------------ | ------------------------------------------------------------ |
| **Host**     | 127.0.0.1    | Flask 与 MyCat 同服                                          |
| **Port**     | **8066**     | **千万别连 3306/3307**                                       |
| **User**     | root         |                                                              |
| **Password** | 123456       |                                                              |
| **Database** | MYETCDB      | 逻辑库名                                                     |
| **Table**    | traffic_data |                                                              |
| **注意事项** | 兼容性       | 必须使用 **MySQL 5.7 兼容驱动**，或在连接串中添加 useSSL=false。若遇 Access Denied，尝试添加客户端参数 --default-auth=mysql_native_password。 |

------



## 🔄 跨服务器联调状态

1. **网络连通性**:
   - pipeline-algo -> db-app: **已通**。
   - db-app 安全组已放行 TCP 8066 端口。
2. **数据链路**:
   - Simulate.py (A) -> Flume (A) -> Kafka (A) -> Flink (B) -> MyCat (B) -> MySQL (B)。
   - **全链路延迟 < 2秒**。
   - **中文显示正常**。

