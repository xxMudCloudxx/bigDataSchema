# pipeline-algo服务器的团队文档 (用于同步给 B、C 同学)

**主题：** `pipeline-algo` 服务器状态更新 - (同学A)

**日期：** 2025-11-18

**概要：**
我已完成 `pipeline-algo` 服务器 的**完整数据管道搭建**。Zookeeper, Kafka, Flume 均已启动并联调通过。数据源 `6.simulate.py` 也已在后台运行。

服务器 1: `pipeline-algo` (计算与消息中心)：112.124.59.217，用户名root，密码B4171yyds

**详细状态：**

1.  **操作系统：** Ubuntu 22.04

2.  **核心依赖：** OpenJDK 1.8 (已安装)

3.  **Zookeeper (v3.5.7)：**

    - **安装目录：** `/usr/local/kafka`

      **配置位置：** `/usr/local/kafka/config/server.properties`

    * 状态：**运行中** (Standalone 模式)
    * 端口：`2181`

4.  **Kafka (v2.4.1)：**

    - **安装目录：** `/usr/local/kafka`
    - **配置位置：** `/usr/local/kafka/config/server.properties`

    * 状态：**运行中**
    * Zookeeper 依赖：已连接 `localhost:2181`
    * **(关键修正)** **网络配置：**
        * 为解决 `LEADER_NOT_AVAILABLE` 错误，已将 `listeners` 配置为 `PLAINTEXT://localhost:9092` INFO KafkaConfig values: ... listeners = PLAINTEXT://localhost:9092]。
        * **已移除** `advertised.listeners` 公网 IP 配置。
    * **内存配置：** 保持 1G 堆内存限制 (`-Xmx1G -Xms1G`)。

5.  **Flume (v1.9.0) 管道：**

    - **安装目录：** `/usr/local/flume`
    - **采集配置：** `/usr/local/flume/jobs/file2kafka.conf`

    * 状态：**运行中**
    * `Source`：`TAILDIR` 成功监控 `/var/log/traffic.log`。
    * `Sink`：`KafkaSink` 成功连接 `localhost:9092`。

6.  **数据源 (`6.simulate.py`)：**

    - **脚本目录：** `~/datapipe/`

    * 状态：**运行中**
    * 正在向 `/var/log/traffic.log` 持续写入数据。

7.  数据管道运维配置

    - 位置：**`/etc/logrotate.d/traffic-pipe`**
    - 这个配置文件里定义了核心策略：
      - **`daily`**：每天检查并切割一次。
      - **`rotate 2`**：只保留最近 2 份日志，更早的自动删除（实现了你说的“2天”清理效果）。
      - **目标文件**：监控的是 `/var/log/traffic.log`。

**下游须知 (同学 B 和 C) - (!!! 重大更新 !!!)**

* 根据我们的架构，你们的 Flink 作业 和 Kafka 运行在**同一台** `pipeline-algo` 服务器上。
* 你们连接 Kafka Broker 的 **唯一地址** 必须是：`localhost:9092`。
* (已废弃) **请不要** 使用 `<公网IP>:9092`，这会导致 `LEADER_NOT_AVAILABLE` 错误。
* 你们要消费的 **Topic** 是：`traffic-raw`。

# db-app服务器的团队文档 (主要是 B、C 同学存储数据使用)



